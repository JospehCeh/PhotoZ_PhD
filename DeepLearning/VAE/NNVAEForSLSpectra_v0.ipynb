{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7762bb4-8955-4545-a340-c61a48760bc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Variational Autoencoders\n",
    "\n",
    "Variational autoencoders view autoencoding from a statistical perspective. Like classical autoencoders, they encode a dataset into a lower dimensional latent space. Additionally, though, variational autoencoders constrain the encoded vectors to roughly follow a probability distribution, e.g. a normal distribution. Here’s an example of a variational autoencoder for the same 1D sequence to sequence monochromatic signal encoding problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77165d98-0046-4d70-818b-d287a0939dd5",
   "metadata": {},
   "source": [
    "https://mlgeophysics.github.io/community/projects/auto-encoder/vae/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332938bc-a315-4bf8-8b17-010092cef9f6",
   "metadata": {},
   "source": [
    "## Variational Autoencoder¶\n",
    "\n",
    "Much of this code is from https://blog.keras.io/building-autoencoders-in-keras.html and https://github.com/keras-team/keras/blob/master/examples/variational_autoencoder.py\n",
    "\n",
    "Tutorials can be found at https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf, https://jaan.io/what-is-variational-autoencoder-vae-tutorial/, and https://arxiv.org/abs/1606.05908\n",
    "\n",
    "This notebook uses the same toy problem as the autoencoding notebook. Here we demonstrate the use of a variational autoencoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db09009d-e006-4be0-baa8-faacbce6ebe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 18:37:33.980208: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "#from keras.models import Input \n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.layers import Dense, LeakyReLU, Lambda, Input\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.losses import mse\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Init Fidle environment\n",
    "import fidle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a849b785-6f6f-4e68-882e-062d59d8061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddfd537-1ff6-418e-b0d1-84bea45c46c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5594784-baec-4d25-b096-935cd23c6f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/sylvie/mambaforge/envs/fidle2023/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow._api.v2.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798447e8-246d-407e-9ea3-4e2760300dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59dfb161-edb6-4906-b645-d0cbe4c05f9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       "div.warn {    \n",
       "    background-color: #fcf2f2;\n",
       "    border-color: #dFb5b4;\n",
       "    border-left: 5px solid #dfb5b4;\n",
       "    padding: 0.5em;\n",
       "    font-weight: bold;\n",
       "    font-size: 1.1em;;\n",
       "    }\n",
       "\n",
       "\n",
       "\n",
       "div.nota {    \n",
       "    background-color: #DAFFDE;\n",
       "    border-left: 5px solid #92CC99;\n",
       "    padding: 0.5em;\n",
       "    }\n",
       "\n",
       "div.todo:before { content:url(data:image/svg+xml;base64,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);\n",
       "    float:left;\n",
       "    margin-right:20px;\n",
       "    margin-top:-20px;\n",
       "    margin-bottom:20px;\n",
       "}\n",
       "div.todo{\n",
       "    font-weight: bold;\n",
       "    font-size: 1.1em;\n",
       "    margin-top:40px;\n",
       "}\n",
       "div.todo ul{\n",
       "    margin: 0.2em;\n",
       "}\n",
       "div.todo li{\n",
       "    margin-left:60px;\n",
       "    margin-top:0;\n",
       "    margin-bottom:0;\n",
       "}\n",
       "\n",
       "div .comment{\n",
       "    font-size:0.8em;\n",
       "    color:#696969;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<br>**FIDLE - Environment initialization**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version              : 2.0b56\n",
      "Run id               : MNIST1\n",
      "Run dir              : ./run/MNIST1\n",
      "Datasets dir         : /Users/sylvie/Documents/fidle-tp/datasets-fidle\n",
      "Start time           : 23/03/23 18:37:35\n",
      "Hostname             : imacdagoret.lal.in2p3.fr (Darwin)\n",
      "Tensorflow log level : Warning + Error  (=1)\n",
      "Update keras cache   : False\n",
      "Save figs            : ./run/MNIST1/figs (False)\n",
      "tensorflow           : 2.12.0\n",
      "numpy                : 1.23.5\n",
      "sklearn              : 1.2.2\n",
      "matplotlib           : 3.7.1\n",
      "pandas               : 1.5.3\n"
     ]
    }
   ],
   "source": [
    "run_id, run_dir, datasets_dir = fidle.init('MNIST1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54dfc75e-b536-499c-9423-7e85951e7972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27f6c5-bea1-45ed-ae43-05750797b712",
   "metadata": {},
   "source": [
    "## generate training, test, and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d900ef-551b-46cd-a805-d7e6da491f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['flambda', 'num', 'quantile', 'redshift', 'wl']>\n"
     ]
    }
   ],
   "source": [
    "hf = h5py.File('SLspectra.hdf5', 'r') \n",
    "data_in = hf['flambda'][:]\n",
    "wl_in = hf['wl'][:]\n",
    "target = hf['quantile'][:]\n",
    "print(hf.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "638a4570-9d25-4916-b283-6c3f0b3ce473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16040f6-adb1-4c57-bd27-4fd2ccccb4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8fda2e-d8da-4388-a440-8346a7682953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NWL = data_in.shape[1]\n",
    "NSAMPL = data_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9341ea45-ddd3-41f8-8ef4-d80dc28ac3c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_in,\n",
    "                                          target,\n",
    "                                          test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "124a8614-ba8e-4e5a-8f27-2806057ff729",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify training parameters and callback functions\n",
    "\n",
    "# batch size for stochastic solver  \n",
    "batch_size = 16\n",
    "\n",
    "# number of times entire dataset is considered in stochastic solver\n",
    "epochs = 50\n",
    "\n",
    "# unique name for the network for saving\n",
    "unique_name = \"NN_VAE_V0\"\n",
    "model_filename = 'model' + unique_name+'.h5'\n",
    "\n",
    "\n",
    "\n",
    "# training history file name\n",
    "history_filename = 'results_'+unique_name+'.npz'\n",
    "\n",
    "# stop early after no improvement past epochs=patience and be verbose\n",
    "earlystopper = EarlyStopping(patience=100, verbose=1)\n",
    "\n",
    "# checkpoint and save model when improvement occurs \n",
    "checkpointer = ModelCheckpoint(model_filename, verbose=1, save_best_only=True)\n",
    "\n",
    "# consolidate callback functions for convenience \n",
    "callbacks = [earlystopper, checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fc6937-e4bd-4fda-ae8d-1a1b64e26e81",
   "metadata": {},
   "source": [
    "Now things get a bit different from a vanilla autoencoder. First, we set the dimensions of the latent space. For this example we can get away with only one dimension. Intuitively, since the only difference between training examples is the phase, we only need one to encode one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921945df-dafe-4765-ae87-a4e649336154",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding dimension; i.e. dimensionality of the latent space\n",
    "encoding_dim=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f49e2c1-1a4c-45b5-ba17-960ffeda9d50",
   "metadata": {},
   "source": [
    "Next we define a function to draw samples from a Gaussian, given the mean and standard deviation. We sample to encode in the latent space. Further, the way this function is defined, it lets us use backpropagation on the mean and standard deviation, even though there's a probabilistic element to this operation (this is the \"reparameterization trick\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a729bcbd-ad54-4ec2-bdb6-2e872904ff8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a function to sample from gaussian, given mean and log variance\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(encoding_dim,))\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6bfac-5066-4d7c-9b4a-2f1412251903",
   "metadata": {},
   "source": [
    "Network structure is similar to the autoencoder. The main difference is in the middle of the network: z_mean and z_log_sigma. These layers encode a mean and log(std) that determine the pdf that we draw the encoding in the latent space from. \n",
    "\n",
    "\n",
    "\n",
    "The \"Lambda\" layer then draws a sample from that pdf, and z is the encoded signal in the latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c38ac5-5a97-4184-a03c-eac760440462",
   "metadata": {},
   "source": [
    "## input layer is full time series of length nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed201cbc-4729-429a-949a-26b0d58d8694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input layer is full time series of length nt\n",
    "inputs = Input((NWL,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f870c4-2a34-42b7-b545-e2c34f30cf17",
   "metadata": {},
   "source": [
    "## encoder hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "776ba9e3-8cfc-4f29-8af6-ecf7b18c6ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder hidden layers\n",
    "encoded = Dense(1024)(inputs) \n",
    "encoded = LeakyReLU(alpha=0.2)(encoded)\n",
    "encoded = Dense(64)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.2)(encoded)\n",
    "encoded = Dense(32)(encoded)\n",
    "encoded = LeakyReLU(alpha=0.2)(encoded)\n",
    "z_mean = Dense(encoding_dim)(encoded)\n",
    "z_log_sigma = Dense(encoding_dim)(encoded)\n",
    "z = Lambda(sampling,output_shape=(encoding_dim,))([z_mean,z_log_sigma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96169a4-fa4f-4a29-b0ca-0b42119657a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## decoder hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00408d87-4795-47ff-b841-e9c34c4d0844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded = Dense(32)(z)\n",
    "decoded = LeakyReLU(alpha=0.2)(decoded)\n",
    "decoded = Dense(64)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.2)(decoded)\n",
    "decoded = Dense(1024)(decoded)\n",
    "decoded = LeakyReLU(alpha=0.2)(decoded)\n",
    "# output layer is same length as input\n",
    "outputs = Dense(NWL,activation='tanh')(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bfabcc-c113-4bb2-b4cc-d5ffa7c77e76",
   "metadata": {},
   "source": [
    "## consolidate to define autoencoder model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f752f71a-5860-4515-8249-7fb7da7471ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# consolidate to define autoencoder model inputs and outputs\n",
    "vae = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70f2106c-541e-43ba-8de5-64beac8be52f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify encoder and decoder model for easy encoding and decoding later\n",
    "encoder = Model(inputs=inputs, outputs=[z_mean,z_log_sigma,z],name='encoder')\n",
    "# create a placeholder for an encoded input\n",
    "encoded_input = Input(shape=(encoding_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21b2edbc-fb66-48ac-a064-9275bfd85d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve the last layers of the autoencoder model\n",
    "decoded_output = vae.layers[-7](encoded_input)\n",
    "decoded_output = vae.layers[-6](decoded_output)\n",
    "decoded_output = vae.layers[-5](decoded_output)\n",
    "decoded_output = vae.layers[-4](decoded_output)\n",
    "decoded_output = vae.layers[-3](decoded_output)\n",
    "decoded_output = vae.layers[-2](decoded_output)\n",
    "decoded_output = vae.layers[-1](decoded_output)\n",
    "# create the decoder model\n",
    "decoder = Model(inputs=encoded_input, outputs=decoded_output, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f86adf25-a12d-4b60-b2e4-c7208efea080",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full autoencoder\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10000)]      0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         10241024    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           65600       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 64)           0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           2080        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 32)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5)            165         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 5)            165         ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 5)            0           ['dense_3[0][0]',                \n",
      "                                                                  'dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           192         ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 64)           2112        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 64)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         66560       ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 1024)         0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 10000)        10250000    ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,627,898\n",
      "Trainable params: 20,627,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Full autoencoder')\n",
    "print(vae.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6191b-4ddf-4fb4-bc9a-4f90d6bd666a",
   "metadata": {},
   "source": [
    "## VAE loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b89a8f-b3ae-432b-8044-0e99964db409",
   "metadata": {},
   "source": [
    "The loss function is another key difference between standard autoencoders and variational autoencoders. A standard autoencoder simply minimizes reconstruction loss. \n",
    "\n",
    "- A variational autoencoder minimizes both reconstruction loss and the KL divergence. \n",
    "\n",
    "- The KL divergence is a measure of how much two probability distributions differ. \n",
    "\n",
    "\n",
    "Minimizing the KL divergence here means that we are encouraging the latent space encodings to have a normal distribution. The regularization parameter balances between reconstruction loss and enforcing a normal distribution in the latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d1ccac0-4d67-4a49-848c-eedb01039085",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify loss\n",
    "# regularization balances signal reconstruction with\n",
    "# a Gaussian distribution in the latent space \n",
    "# regularization = 10\n",
    "regularization = 10\n",
    "\n",
    "def vae_loss(input_img, output):\n",
    "    # compute the average MSE error, then scale it up, ie. simply sum on all axes\n",
    "    reconstruction_loss = K.sum(K.square(output-input_img))\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_sigma - K.square(z_mean) - K.square(K.exp(z_log_sigma)), axis=-1)\n",
    "    # return the average loss over all images in batch\n",
    "    total_loss = K.mean(reconstruction_loss + regularization*kl_loss)    \n",
    "    return total_loss\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss, metrics=['mse'],experimental_run_tf_function=False,run_eagerly=False)\n",
    "vae.run_eagerly = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6b3e85-c81e-4474-a8a5-fece81413716",
   "metadata": {},
   "source": [
    "## train variational autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff91d562-d98f-46e3-a32a-cc4f30a71b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440 samples, validate on 110 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 18:37:36.916056: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Adam/dense_7/kernel/v/Assign' id:690 op device:{requested: '', assigned: ''} def:{{{node training/Adam/dense_7/kernel/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Adam/dense_7/kernel/v, training/Adam/dense_7/kernel/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - ETA: 0s - loss: 45.9426 - mean_squared_error: 2.9866e-04\n",
      "Epoch 1: val_loss improved from inf to 9.48923, saving model to modelNN_VAE_V0.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sylvie/mambaforge/envs/fidle2023/lib/python3.9/site-packages/keras/engine/training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2023-03-23 18:37:38.802991: W tensorflow/c/c_api.cc:300] Operation '{name:'loss/mul' id:288 op device:{requested: '', assigned: ''} def:{{{node loss/mul}} = Mul[T=DT_FLOAT, _has_manual_control_dependencies=true](loss/mul/x, loss/dense_8_loss/value)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/440 [==============================] - 4s 8ms/sample - loss: 45.9426 - mean_squared_error: 2.9866e-04 - val_loss: 9.4892 - val_mean_squared_error: 5.4343e-05\n",
      "Epoch 2/50\n",
      "440/440 [==============================] - ETA: 0s - loss: 8.7704 - mean_squared_error: 4.8855e-05\n",
      "Epoch 2: val_loss improved from 9.48923 to 2.28977, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: 8.7704 - mean_squared_error: 4.8855e-05 - val_loss: 2.2898 - val_mean_squared_error: 1.7133e-05\n",
      "Epoch 3/50\n",
      "440/440 [==============================] - ETA: 0s - loss: 0.3670 - mean_squared_error: 1.6544e-05\n",
      "Epoch 3: val_loss improved from 2.28977 to -1.65643, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 5s 10ms/sample - loss: 0.3670 - mean_squared_error: 1.6544e-05 - val_loss: -1.6564 - val_mean_squared_error: 1.1040e-05\n",
      "Epoch 4/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -1.4056 - mean_squared_error: 1.3328e-05\n",
      "Epoch 4: val_loss improved from -1.65643 to -1.76028, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -1.4056 - mean_squared_error: 1.3328e-05 - val_loss: -1.7603 - val_mean_squared_error: 1.1055e-05\n",
      "Epoch 5/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -2.4300 - mean_squared_error: 7.4692e-06\n",
      "Epoch 5: val_loss improved from -1.76028 to -3.11468, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 3s 8ms/sample - loss: -2.4300 - mean_squared_error: 7.4692e-06 - val_loss: -3.1147 - val_mean_squared_error: 4.1043e-06\n",
      "Epoch 6/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -2.9900 - mean_squared_error: 4.9896e-06\n",
      "Epoch 6: val_loss improved from -3.11468 to -3.12690, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -2.9900 - mean_squared_error: 4.9896e-06 - val_loss: -3.1269 - val_mean_squared_error: 4.3233e-06\n",
      "Epoch 7/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.1764 - mean_squared_error: 4.0033e-06\n",
      "Epoch 7: val_loss improved from -3.12690 to -3.31008, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -3.1764 - mean_squared_error: 4.0033e-06 - val_loss: -3.3101 - val_mean_squared_error: 3.1259e-06\n",
      "Epoch 8/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.3237 - mean_squared_error: 3.1077e-06\n",
      "Epoch 8: val_loss improved from -3.31008 to -3.48080, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 10ms/sample - loss: -3.3237 - mean_squared_error: 3.1077e-06 - val_loss: -3.4808 - val_mean_squared_error: 2.1541e-06\n",
      "Epoch 9/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.2536 - mean_squared_error: 3.5627e-06\n",
      "Epoch 9: val_loss improved from -3.48080 to -3.49875, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 10ms/sample - loss: -3.2536 - mean_squared_error: 3.5627e-06 - val_loss: -3.4987 - val_mean_squared_error: 2.0208e-06\n",
      "Epoch 10/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.1889 - mean_squared_error: 3.9287e-06\n",
      "Epoch 10: val_loss did not improve from -3.49875\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.1889 - mean_squared_error: 3.9287e-06 - val_loss: -3.4208 - val_mean_squared_error: 2.4382e-06\n",
      "Epoch 11/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.1737 - mean_squared_error: 4.0690e-06\n",
      "Epoch 11: val_loss did not improve from -3.49875\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.1737 - mean_squared_error: 4.0690e-06 - val_loss: -2.5224 - val_mean_squared_error: 8.2513e-06\n",
      "Epoch 12/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -2.8626 - mean_squared_error: 6.1078e-06\n",
      "Epoch 12: val_loss did not improve from -3.49875\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -2.8626 - mean_squared_error: 6.1078e-06 - val_loss: -2.9232 - val_mean_squared_error: 5.4862e-06\n",
      "Epoch 13/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.0112 - mean_squared_error: 4.8908e-06\n",
      "Epoch 13: val_loss did not improve from -3.49875\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.0112 - mean_squared_error: 4.8908e-06 - val_loss: -3.4240 - val_mean_squared_error: 2.3704e-06\n",
      "Epoch 14/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.3397 - mean_squared_error: 2.9460e-06\n",
      "Epoch 14: val_loss did not improve from -3.49875\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.3397 - mean_squared_error: 2.9460e-06 - val_loss: -3.4958 - val_mean_squared_error: 2.0193e-06\n",
      "Epoch 15/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.4642 - mean_squared_error: 2.2709e-06\n",
      "Epoch 15: val_loss improved from -3.49875 to -3.55577, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -3.4642 - mean_squared_error: 2.2709e-06 - val_loss: -3.5558 - val_mean_squared_error: 1.6967e-06\n",
      "Epoch 16/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.5178 - mean_squared_error: 1.9667e-06\n",
      "Epoch 16: val_loss improved from -3.55577 to -3.63692, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -3.5178 - mean_squared_error: 1.9667e-06 - val_loss: -3.6369 - val_mean_squared_error: 1.2294e-06\n",
      "Epoch 17/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6137 - mean_squared_error: 1.3672e-06\n",
      "Epoch 17: val_loss did not improve from -3.63692\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6137 - mean_squared_error: 1.3672e-06 - val_loss: -3.6256 - val_mean_squared_error: 1.3116e-06\n",
      "Epoch 18/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6658 - mean_squared_error: 1.0642e-06\n",
      "Epoch 18: val_loss did not improve from -3.63692\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6658 - mean_squared_error: 1.0642e-06 - val_loss: -3.5578 - val_mean_squared_error: 1.7556e-06\n",
      "Epoch 19/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6100 - mean_squared_error: 1.3984e-06\n",
      "Epoch 19: val_loss improved from -3.63692 to -3.70068, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 3s 8ms/sample - loss: -3.6100 - mean_squared_error: 1.3984e-06 - val_loss: -3.7007 - val_mean_squared_error: 8.4800e-07\n",
      "Epoch 20/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.5999 - mean_squared_error: 1.4594e-06\n",
      "Epoch 20: val_loss did not improve from -3.70068\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.5999 - mean_squared_error: 1.4594e-06 - val_loss: -3.6716 - val_mean_squared_error: 1.0248e-06\n",
      "Epoch 21/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7342 - mean_squared_error: 6.3498e-07\n",
      "Epoch 21: val_loss did not improve from -3.70068\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7342 - mean_squared_error: 6.3498e-07 - val_loss: -3.6159 - val_mean_squared_error: 1.4100e-06\n",
      "Epoch 22/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6691 - mean_squared_error: 1.0347e-06\n",
      "Epoch 22: val_loss did not improve from -3.70068\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6691 - mean_squared_error: 1.0347e-06 - val_loss: -3.6480 - val_mean_squared_error: 1.2076e-06\n",
      "Epoch 23/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7194 - mean_squared_error: 7.4694e-07\n",
      "Epoch 23: val_loss improved from -3.70068 to -3.71890, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -3.7194 - mean_squared_error: 7.4694e-07 - val_loss: -3.7189 - val_mean_squared_error: 7.3281e-07\n",
      "Epoch 24/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7008 - mean_squared_error: 8.3911e-07\n",
      "Epoch 24: val_loss improved from -3.71890 to -3.74442, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 5s 11ms/sample - loss: -3.7008 - mean_squared_error: 8.3911e-07 - val_loss: -3.7444 - val_mean_squared_error: 5.7128e-07\n",
      "Epoch 25/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7353 - mean_squared_error: 6.2656e-07\n",
      "Epoch 25: val_loss improved from -3.74442 to -3.74486, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 9ms/sample - loss: -3.7353 - mean_squared_error: 6.2656e-07 - val_loss: -3.7449 - val_mean_squared_error: 5.7000e-07\n",
      "Epoch 26/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7524 - mean_squared_error: 5.2029e-07\n",
      "Epoch 26: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7524 - mean_squared_error: 5.2029e-07 - val_loss: -3.6917 - val_mean_squared_error: 8.9936e-07\n",
      "Epoch 27/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6860 - mean_squared_error: 9.2999e-07\n",
      "Epoch 27: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6860 - mean_squared_error: 9.2999e-07 - val_loss: -3.7273 - val_mean_squared_error: 6.7292e-07\n",
      "Epoch 28/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6385 - mean_squared_error: 1.2390e-06\n",
      "Epoch 28: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6385 - mean_squared_error: 1.2390e-06 - val_loss: -3.5370 - val_mean_squared_error: 1.8621e-06\n",
      "Epoch 29/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.6626 - mean_squared_error: 1.0825e-06\n",
      "Epoch 29: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.6626 - mean_squared_error: 1.0825e-06 - val_loss: -3.7123 - val_mean_squared_error: 7.7297e-07\n",
      "Epoch 30/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7314 - mean_squared_error: 6.5861e-07\n",
      "Epoch 30: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7314 - mean_squared_error: 6.5861e-07 - val_loss: -3.6602 - val_mean_squared_error: 1.1022e-06\n",
      "Epoch 31/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7574 - mean_squared_error: 5.0381e-07\n",
      "Epoch 31: val_loss did not improve from -3.74486\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7574 - mean_squared_error: 5.0381e-07 - val_loss: -3.7325 - val_mean_squared_error: 6.5218e-07\n",
      "Epoch 32/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7258 - mean_squared_error: 6.8674e-07\n",
      "Epoch 32: val_loss improved from -3.74486 to -3.75548, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 3s 8ms/sample - loss: -3.7258 - mean_squared_error: 6.8674e-07 - val_loss: -3.7555 - val_mean_squared_error: 5.0307e-07\n",
      "Epoch 33/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7451 - mean_squared_error: 5.7917e-07\n",
      "Epoch 33: val_loss improved from -3.75548 to -3.76163, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 8ms/sample - loss: -3.7451 - mean_squared_error: 5.7917e-07 - val_loss: -3.7616 - val_mean_squared_error: 4.6267e-07\n",
      "Epoch 34/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7711 - mean_squared_error: 4.0688e-07\n",
      "Epoch 34: val_loss did not improve from -3.76163\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7711 - mean_squared_error: 4.0688e-07 - val_loss: -3.7521 - val_mean_squared_error: 5.2511e-07\n",
      "Epoch 35/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7801 - mean_squared_error: 3.5164e-07\n",
      "Epoch 35: val_loss improved from -3.76163 to -3.77943, saving model to modelNN_VAE_V0.h5\n",
      "440/440 [==============================] - 4s 8ms/sample - loss: -3.7801 - mean_squared_error: 3.5164e-07 - val_loss: -3.7794 - val_mean_squared_error: 3.5698e-07\n",
      "Epoch 36/50\n",
      "440/440 [==============================] - ETA: 0s - loss: -3.7511 - mean_squared_error: 5.3078e-07\n",
      "Epoch 36: val_loss did not improve from -3.77943\n",
      "440/440 [==============================] - 2s 4ms/sample - loss: -3.7511 - mean_squared_error: 5.3078e-07 - val_loss: -3.7435 - val_mean_squared_error: 5.7834e-07\n",
      "Epoch 37/50\n",
      "368/440 [========================>.....] - ETA: 0s - loss: -3.7612 - mean_squared_error: 4.6405e-07"
     ]
    }
   ],
   "source": [
    "# train variational autoencoder\n",
    "results = vae.fit(x_train,x_train,\n",
    "                      shuffle=True,\n",
    "                      batch_size = batch_size, \n",
    "                      epochs = epochs,\n",
    "                      validation_data = (x_test,x_test),\n",
    "                      callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6190ae-c76f-4052-8b62-d60931fe07c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# QC training and validation curves (should follow eachother)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(results.history['val_loss'], label='val')\n",
    "plt.plot(results.history['loss'], label='train')\n",
    "plt.xlabel('epoch index')\n",
    "plt.ylabel('loss value (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75492832-c5a7-4699-ab0f-a890e5ddc1cd",
   "metadata": {},
   "source": [
    "## First, let's check to see how well the encoder is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca6c08-0d9f-4972-a14c-ccada33c1f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_test = np.array(encoder.predict(x_test))\n",
    "vae_test = vae.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f829b-f9eb-4e00-a9a2-7c8fb0d50dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x_test[2],label='true signal')\n",
    "plt.plot(vae_test[2],label='encoded-decoded signal',alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f13770f-f8c7-4864-9b44-a50fa5bb8f0f",
   "metadata": {},
   "source": [
    "## Now let's look at the distribution of samples in the latent space, to see how gaussian it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7221cdd5-9611-40d1-b35b-fca15d2033ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "n,bins,patches=plt.hist(encoded_test[2,:,:].flatten(),bins=100,density=True)\n",
    "plt.plot(bins,scipy.stats.norm.pdf(bins,0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a7ce18-c555-4c91-954f-1a256caf75e1",
   "metadata": {},
   "source": [
    "## Now let's see how the decoded signal depends on the latent vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39d5037-4b94-4094-a12e-f4661b7b968f",
   "metadata": {},
   "source": [
    "Interestingly, the autoencoder has learned to use the latent vector (value in this case, since we specified an encoding dimension of 1) as a proxy for phase. As the latent value changes, the phase of the decoded signal changes. Latent values near zero reproduce a sine wave well, while values far from zero produce signals that aren't exactly sinusoidal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4855d0-4b37-47a0-948a-ca2882ac0e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fidle2023",
   "language": "python",
   "name": "fidle2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
