{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be22337f-1e77-4236-be4d-23f2b21d5658",
   "metadata": {},
   "source": [
    "# Test VAE CNN1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5437339b-4227-4f62-b0ef-a14f2869ce02",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/43103980/one-dimensional-convolutional-variational-autoencoder-in-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c761c76-bc7e-458d-9220-3c59d12398d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "# Keras uses TensforFlow backend as default\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdce53d-c025-4b81-aebc-2658792617d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File('SLspectra.hdf5', 'r') as hf:\n",
    "    data_in = hf['flambda'][:]\n",
    "    wl_in = hf['wl'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bb878dd-1030-4d5d-b25e-d88cb0e2a03c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a20b6fe-9d23-43ac-89a8-7482a63d7c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_in = data_in.reshape(data_in.shape[0],data_in.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80742218-eb9a-4fd6-9bc3-19e0dd3b8d90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 10000, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44cec904-c971-4269-9a35-f0327c25714c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NSIZE = data_in.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382e75f-8109-4788-8ff1-f8844b833db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of convolutional filters to use\n",
    "filters = 64\n",
    "# Convolution kernel size\n",
    "num_conv = 6\n",
    "# Set batch size\n",
    "batch_size = 100\n",
    "# Decoder output dimensionality\n",
    "decOutput = 10\n",
    "\n",
    "latent_dim = 5\n",
    "intermediate_dim = 256\n",
    "epsilon_std = 1.0\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a7a15fc-7f29-493e-b7d4-00c754dfa5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(NSIZE,1))\n",
    "# Play around with padding here, not sure what to go with.\n",
    "conv_1 = Conv1D(1,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same', \n",
    "                activation='relu')(x)\n",
    "conv_2 = Conv1D(filters,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same', \n",
    "                activation='relu',\n",
    "                strides=1)(conv_1)\n",
    "flat = Flatten()(conv_2) # Since we are passing flat data anyway, we probably don't need this.\n",
    "hidden = Dense(intermediate_dim, activation='relu')(flat)\n",
    "z_mean = Dense(latent_dim)(hidden)\n",
    "z_log_var = Dense(latent_dim)(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b7ac156-0a91-47c3-be14-c7b8f8ba5735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var ) * epsilon # the original VAE divides z_log_var with two -- why?\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_var])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "844b3cf7-5deb-4757-ac5e-1bcb5d3dc7b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we instantiate these layers separately so as to reuse them later\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(NSIZE, activation='sigmoid')\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "x_decoded_mean = Reshape([NSIZE,1])(x_decoded_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ccae89d-3206-43e3-b958-16cee8b13639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = original_dim * metrics.binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1) # Double check wtf this is supposed to be\n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7294294-2035-4b68-ab04-6d86740a9b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 10000, 1)]   0           []                               \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 10000, 1)     7           ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 10000, 64)    448         ['conv1d_11[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 640000)       0           ['conv1d_12[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 256)          163840256   ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 5)            1285        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 5)            1285        ['dense_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_2 (Lambda)              (100, 5)             0           ['dense_11[0][0]',               \n",
      "                                                                  'dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (100, 256)           1536        ['lambda_2[0][0]']               \n",
      "                                                                                                  \n",
      " dense_16 (Dense)               (100, 10000)         2570000     ['dense_15[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (100, 10000, 1)      0           ['dense_16[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 166,414,817\n",
      "Trainable params: 166,414,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss) # 'rmsprop'\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e774de66-e9af-449e-a0f7-80fe90a90c96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (550, 10000, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = data_in \n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "\n",
    "print('x_train.shape:', x_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2e0499a-c9dc-40a2-99a1-fbf2b6098585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 317, in __call__\n        self._total_loss_mean.update_state(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 477, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 283, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_8'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(N\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/cq/vms8st5136z3q5xx4rd9xqfr0000gw/T/__autograph_generated_filen5kdfjvn.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 317, in __call__\n        self._total_loss_mean.update_state(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n        update_op = update_state_fn(*args, **kwargs)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n        return ag_update_state(*args, **kwargs)\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/metrics/base_metric.py\", line 477, in update_state  **\n        sample_weight = tf.__internal__.ops.broadcast_weights(\n    File \"/Users/dagoret/opt/anaconda3/envs/fidle23/lib/python3.9/site-packages/keras/engine/keras_tensor.py\", line 283, in __array__\n        raise TypeError(\n\n    TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(), dtype=tf.float32, name=None), name='Placeholder:0', description=\"created by layer 'tf.cast_8'\"), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "epochs = 2\n",
    "batch_size = int(N/10)\n",
    "vae.fit(x_train[0:N,:], x_train[0:N,:],\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea4ecf-fafa-4f45-86df-c1becea4e705",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fidle2023",
   "language": "python",
   "name": "fidle2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
